{
  "sources": [
    {
      "title": "Release notes from osmosfeed",
      "feedUrl": "https://github.com/osmoscraft/osmosfeed/releases.atom",
      "siteUrl": "https://github.com/osmoscraft/osmosfeed/releases",
      "articles": []
    },
    {
      "title": "Towards Data Science - Medium",
      "feedUrl": "https://towardsdatascience.com/feed",
      "siteUrl": "https://towardsdatascience.com?source=rss----7f60cf5620c9---4",
      "articles": [
        {
          "id": "https://medium.com/p/0230ba53965b",
          "author": "Chaim Rand",
          "description": "Optimizing the use of limited AI training accelerators",
          "link": "https://towardsdatascience.com/maximizing-the-utility-of-scarce-ai-resources-a-kubernetes-approach-0230ba53965b?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T18:30:22.000Z",
          "wordCount": 6536,
          "title": "Maximizing the Utility of Scarce AI Resources: A Kubernetes Approach",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*76mGrS7mPXEHrLP3"
        },
        {
          "id": "https://medium.com/p/a94974c1ad38",
          "author": "Aparna Dhinakaran",
          "description": "Evaluating the performance of RAG systems",
          "link": "https://towardsdatascience.com/the-needle-in-a-haystack-test-a94974c1ad38?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T18:23:01.000Z",
          "wordCount": 4587,
          "title": "The Needle In a Haystack Test",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1016/1*LYDN7bgP6r3q_2EsNdQPNA.png"
        },
        {
          "id": "https://medium.com/p/e83a524a5a13",
          "author": "Patrick Beukema",
          "description": "Practical advice on harnessing LLMs to enhance efficiency and significantly streamline the development process.",
          "link": "https://towardsdatascience.com/accelerating-engineering-with-llms-e83a524a5a13?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T18:20:13.000Z",
          "wordCount": 8604,
          "title": "Accelerating Engineering with LLMs",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1024/1*Qfr4YUO5ORWHjV6DB2h8Ng.png"
        },
        {
          "id": "https://medium.com/p/39cf3671f8a0",
          "author": "Samuel Flender",
          "description": "A deep-dive into the technology that paved the way for the most capable LLMs in the industry today\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/the-rise-of-sparse-mixtures-of-experts-switch-transformers-39cf3671f8a0?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T18:16:56.000Z",
          "wordCount": 1398,
          "title": "The Rise of Sparse Mixtures of Experts: Switch Transformers",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*HhVrQOIQ2jwHt6AZttX3WQ.png"
        },
        {
          "id": "https://medium.com/p/eb08472ee9be",
          "author": "Angelica Lo Duca",
          "description": "A tutorial in Python using the jellyfish library to calculate the similarity between two strings\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/three-ways-to-calculate-the-similarity-between-two-strings-eb08472ee9be?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T18:10:32.000Z",
          "wordCount": 1347,
          "title": "Three Ways to Calculate the Similarity Between Two Strings",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*-BuCKSxckjZ2cxIh"
        },
        {
          "id": "https://medium.com/p/12f0fa770cf0",
          "author": "TDS Editors",
          "description": "Our weekly selection of must-read Editors’ Picks and original features",
          "link": "https://towardsdatascience.com/things-you-can-do-with-python-advanced-and-special-use-cases-12f0fa770cf0?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T14:31:36.000Z",
          "wordCount": 1937,
          "title": "Things You Can Do with Python: Advanced and Special Use Cases",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*Dj4qMUTf4hxobzsi"
        },
        {
          "id": "https://medium.com/p/d05cd5eb0927",
          "author": "Vassily Morozov",
          "description": "After a credit card? An insurance policy? Ever wondered about the three-digit number that shapes these decisions?",
          "link": "https://towardsdatascience.com/unlocking-insights-building-a-scorecard-with-logistic-regression-d05cd5eb0927?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T06:18:46.000Z",
          "wordCount": 5058,
          "title": "Unlocking Insights: Building a Scorecard with Logistic Regression",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1024/1*EKBruMDrZk0g-_W4xgLfaA.jpeg"
        },
        {
          "id": "https://medium.com/p/923aa13143d4",
          "author": "Cameron R. Wolfe, Ph.D.",
          "description": "Modern policy gradient algorithms and their application to language models…\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/proximal-policy-optimization-ppo-the-key-to-llm-alignment-923aa13143d4?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T05:50:12.000Z",
          "wordCount": 1476,
          "title": "Proximal Policy Optimization (PPO): The Key to LLM Alignment",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*QJBULLQrZ8cYuHc1it07TQ.jpeg"
        },
        {
          "id": "https://medium.com/p/c4bd6ef20263",
          "author": "Patrick Altmeyer",
          "description": "Faithful model explanations through energy-based conformal counterfactuals\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/ecccos-from-the-black-box-c4bd6ef20263?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T05:37:22.000Z",
          "wordCount": 1487,
          "title": "ECCCos from the Black Box",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/0*6UmsyfXiM1WuO6tl.png"
        },
        {
          "id": "https://medium.com/p/ddde83e24e8e",
          "author": "Guillaume Colley",
          "description": "The author details two examples of defining customer churn in contexts where it is not explicit: Retail and Banking.\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/customer-attrition-how-to-define-churn-when-customers-do-not-tell-theyre-leaving-ddde83e24e8e?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-15T04:49:13.000Z",
          "wordCount": 1422,
          "title": "Customer Attrition: How to Define Churn When Customers Do Not Tell They’re Leaving",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1078/1*vD9CGjg2yhJv5RAWbQ201g.png"
        },
        {
          "id": "https://medium.com/p/8bcbcb37a60f",
          "author": "Eivind Kjosbakken",
          "description": "Creating quality embeddings is an essential part of most AI systems, and so this article walks you through how to ensure their quality.\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/how-to-improve-ai-performance-by-understanding-embedding-quality-8bcbcb37a60f?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-14T19:31:31.000Z",
          "wordCount": 1427,
          "title": "How To Improve AI Performance By Understanding Embedding Quality",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1024/0*1T4O7HTe3_FtvsBH"
        },
        {
          "id": "https://medium.com/p/96df01873023",
          "author": "Nithhyaa Ramamoorthy",
          "description": "A simple and effective Framework to build confidence in your data presentations",
          "link": "https://towardsdatascience.com/a-data-persons-guide-to-tackling-analysis-paralysis-96df01873023?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-14T19:28:06.000Z",
          "wordCount": 4970,
          "title": "A Data Person’s Guide to Tackling Analysis Paralysis",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:882/1*TGBEKNpB2A8fnTfp4QGSkQ.png"
        },
        {
          "id": "https://medium.com/p/3001f54c48e9",
          "author": "Yoann Mocquin",
          "description": "Always keep a dummy by your side.\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/the-dummy-models-of-scikit-learn-3001f54c48e9?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-14T09:06:17.000Z",
          "wordCount": null,
          "title": "The Dummy models of Scikit-learn",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/a54701d1b621",
          "author": "Andrew Skabar, PhD",
          "description": "",
          "link": "https://towardsdatascience.com/evaluating-synthetic-data-the-million-dollar-question-a54701d1b621?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-14T06:12:20.000Z",
          "wordCount": null,
          "title": "Evaluating Synthetic Data — The Million Dollar Question",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/360dce356df5",
          "author": "Mikhail Sarafanov",
          "description": "",
          "link": "https://towardsdatascience.com/stream-ordering-how-and-why-a-geo-scientist-sometimes-needed-to-rank-rivers-on-a-map-360dce356df5?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-14T06:09:20.000Z",
          "wordCount": null,
          "title": "Stream Ordering: How And Why a Geo-scientist Sometimes Needed to Rank Rivers on a Map",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/41425a40d7d0",
          "author": "Vincent Koc",
          "description": "Architecture patterns and mental models for working with Large Language Models",
          "link": "https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T23:19:59.000Z",
          "wordCount": 3759,
          "title": "Generative AI Design Patterns: A Comprehensive Guide",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*2tBQkVvC-_sHACgSs0ouug.png"
        },
        {
          "id": "https://medium.com/p/ee11ab5f9f20",
          "author": "Sachin Date",
          "description": "The life and times of Abraham De Moivre, his famous theorem, and how it set the stage for the discovery of the Central Limit Theorem",
          "link": "https://towardsdatascience.com/abraham-de-moivre-his-famous-theorem-and-the-birth-of-the-normal-curve-ee11ab5f9f20?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T21:37:50.000Z",
          "wordCount": 8015,
          "title": "Abraham De Moivre, His Famous Theorem, and the Birth of the Normal Curve",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*SoJHemrSFz0wWPxZl3q4wg.jpeg"
        },
        {
          "id": "https://medium.com/p/cf3682f8563b",
          "author": "Robert A. Gonsalves",
          "description": "Transforming your ideas into tangible artifacts using Midjourney and open-source projects: Shap-E, MVDream, and threestudio\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/molding-the-imagination-using-ai-to-create-new-3d-printable-objects-cf3682f8563b?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T21:31:18.000Z",
          "wordCount": 1497,
          "title": "Molding the Imagination: Using AI to Create New 3D-Printable Objects",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*sao9nlpIadkA3dzQig2qHQ.jpeg"
        },
        {
          "id": "https://medium.com/p/e823535e0eb1",
          "author": "LucianoSphere (Luciano Abriata, PhD)",
          "description": "A careful selection looking for performance, flexibility, and richness of features.\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/the-most-advanced-libraries-for-data-visualization-and-analysis-on-the-web-e823535e0eb1?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T20:39:41.000Z",
          "wordCount": 1520,
          "title": "The Most Advanced Libraries for Data Visualization and Analysis on the Web",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*Cpgpk7Sl0hGofvcE7OEWMA.png"
        },
        {
          "id": "https://medium.com/p/cb1bd2f3f4bb",
          "author": "Yennie Jun",
          "description": "How well can AI models solve (and create) rebus puzzles?\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/measuring-ais-creativity-with-visual-word-puzzles-cb1bd2f3f4bb?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T20:10:28.000Z",
          "wordCount": null,
          "title": "Measuring AI’s Creativity with Visual Word Puzzles",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/0af4ea38f7b5",
          "author": "John Leung",
          "description": "Explore the potentials and constraints of LangChain for customer analytics, accompanied by practical implementation codes\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/performing-customer-analytics-with-langchain-and-llms-0af4ea38f7b5?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T19:34:16.000Z",
          "wordCount": null,
          "title": "Performing Customer Analytics with LangChain and LLMs",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/5c1db85984a1",
          "author": "Okan Bulut",
          "description": "",
          "link": "https://towardsdatascience.com/lexicon-based-sentiment-analysis-using-r-5c1db85984a1?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T17:50:27.000Z",
          "wordCount": null,
          "title": "Lexicon-Based Sentiment Analysis Using R",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/795582423666",
          "author": "Cristian Leo",
          "description": "",
          "link": "https://towardsdatascience.com/the-math-and-code-behind-k-means-clustering-795582423666?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T15:21:24.000Z",
          "wordCount": null,
          "title": "The Math and Code Behind K-Means Clustering",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/9d50b36bcbd3",
          "author": "Sofya Lipnitskaya",
          "description": "",
          "link": "https://towardsdatascience.com/bird-by-bird-using-finite-automata-9d50b36bcbd3?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T15:15:51.000Z",
          "wordCount": null,
          "title": "Finite Automata Simulation for Leveraging AI-Assisted Systems",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/9afdfaf2bd7c",
          "author": "Marco Peixeiro",
          "description": "Explore the architecture of Lag-Llama and learn to apply it in a forecasting project using Python\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/lag-llama-open-source-foundation-model-for-time-series-forecasting-9afdfaf2bd7c?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T14:52:49.000Z",
          "wordCount": null,
          "title": "Lag-Llama: Open-Source Foundation Model for Time Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/e62531bca7a0",
          "author": "Rami Krispin",
          "description": "",
          "link": "https://towardsdatascience.com/setting-a-dockerized-python-environment-the-hard-way-e62531bca7a0?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T14:45:42.000Z",
          "wordCount": null,
          "title": "Setting A Dockerized Python Environment — The Hard Way",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/afd97fce8fb5",
          "author": "Mariya Mansurova",
          "description": "",
          "link": "https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T08:03:13.000Z",
          "wordCount": null,
          "title": "Text Embeddings: Comprehensive Guide",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/71f714440923",
          "author": "Jarom Hulet",
          "description": "Understanding EMD through theory and from-scratch calculation\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/comparison-of-distributions-with-earth-movers-distance-71f714440923?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T07:55:44.000Z",
          "wordCount": null,
          "title": "Comparison of Distributions with Earth Mover’s Distance",
          "imageUrl": null
        },
        {
          "id": "https://medium.com/p/465970a969e0",
          "author": "Ugur Yildirim",
          "description": "How to know the unknowable in observational studies",
          "link": "https://towardsdatascience.com/sensitivity-analysis-for-unobserved-confounding-465970a969e0?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-13T00:27:50.000Z",
          "wordCount": 5372,
          "title": "Sensitivity Analysis for Unobserved Confounding",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*pw5JJ7_hGcYcTWNoyZsfzQ.png"
        },
        {
          "id": "https://medium.com/p/2902224aabf3",
          "author": "Stefano Bosisio",
          "description": "In this first article, we’re exploring Apache Beam, from a simple pipeline to a more complicated one, using GCP Dataflow. Let’s learn what…\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/apache-beam-data-processing-data-pipelines-dataflow-and-flex-templates-2902224aabf3?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T19:40:21.000Z",
          "wordCount": 1464,
          "title": "Apache Beam: Data Processing, Data Pipelines, Dataflow and Flex Templates",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*qDe_sNC7PPh3fU0KWs04Ug.jpeg"
        },
        {
          "id": "https://medium.com/p/a7dc47723788",
          "author": "Claudia Ng",
          "description": "Learn to build a Graph Convolutional Network that can handle heterogeneous graph data for link prediction\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/how-to-build-a-graph-based-neural-network-for-anomaly-detection-in-6-steps-a7dc47723788?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T19:22:38.000Z",
          "wordCount": 1414,
          "title": "How to Build a Graph-based Neural Network for Anomaly Detection in 6 Steps",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:640/1*Lb_4cCQckr6i7aDoJ2SN5w.png"
        },
        {
          "id": "https://medium.com/p/17f84378430b",
          "author": "Toon Beerten",
          "description": "A hands-on marketing use case\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/powerful-collaboration-of-ai-agents-with-crewai-17f84378430b?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T19:12:44.000Z",
          "wordCount": 1355,
          "title": "Powerful Collaboration of AI Agents with CrewAI",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*40kwxJ7oZ1kTAJsRt_2bow.png"
        },
        {
          "id": "https://medium.com/p/a4e876f9a532",
          "author": "Mohammed Mohammed",
          "description": "A constructive approach to measuring distribution differences.",
          "link": "https://towardsdatascience.com/understanding-kl-divergence-intuitively-a4e876f9a532?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T19:05:57.000Z",
          "wordCount": 3032,
          "title": "Understanding KL Divergence Intuitively",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*RlzqwDFtqqNYQjD2"
        },
        {
          "id": "https://medium.com/p/a57512cabd69",
          "author": "Mahyar Aboutalebi, Ph.D.",
          "description": "Learn how to work with Lexcube, a Python package for data visualization in the space-time domain!\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/3d-visualization-of-geospatial-big-data-by-lexcube-python-a57512cabd69?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T16:09:16.000Z",
          "wordCount": 1471,
          "title": "3D Visualization of Geospatial Big Data by Lexcube! (Python)",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*ThD3jbF6-ifOSyZVtzhdXg.png"
        },
        {
          "id": "https://medium.com/p/a5d7b15f3d1d",
          "author": "Jacky Kaub",
          "description": "Why distribution drifts can really hurt your models\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/the-biggest-weakness-of-boosting-trees-a5d7b15f3d1d?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T15:24:32.000Z",
          "wordCount": 1389,
          "title": "The Biggest Weakness Of Boosting Trees",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*bcxyWsq_OvXuZZkT"
        },
        {
          "id": "https://medium.com/p/ccb3a116f6eb",
          "author": "Conor O'Sullivan",
          "description": "Automation, machine learning and LLMs in the chip industry\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/7-lessons-from-an-ml-internship-at-intel-ccb3a116f6eb?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T14:37:22.000Z",
          "wordCount": 1403,
          "title": "7 Lessons from an ML Internship at Intel",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*D7KYKmCGk2NkPMdb6PFw0Q.png"
        },
        {
          "id": "https://medium.com/p/ea0f9ce61719",
          "author": "Christopher Tao",
          "description": "Get Holidays from Any Country, Any Year, Any date\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/python-could-know-your-holidays-no-matter-which-country-you-live-ea0f9ce61719?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T14:37:12.000Z",
          "wordCount": 1388,
          "title": "Python Could Know Your Holidays No Matter Which Country You Live",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*pk-kVwA2UxPMtRC_k1ED1Q.jpeg"
        },
        {
          "id": "https://medium.com/p/d3b3b28ba121",
          "author": "Marcin Kozak",
          "description": "The article shows simple examples of flat and nested recursion patterns in Python.\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/recursion-in-python-demystified-d3b3b28ba121?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-12T13:06:35.000Z",
          "wordCount": 1447,
          "title": "Recursion in Python Demystified",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*8EKWgHhKoScGLrZW"
        },
        {
          "id": "https://medium.com/p/769f43b46779",
          "author": "Márton Kardos",
          "description": "Understand Semantic Structures with Transformers and Topic Modeling",
          "link": "https://towardsdatascience.com/semantic-signal-separation-769f43b46779?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-11T15:55:45.000Z",
          "wordCount": 5294,
          "title": "Semantic Signal Separation",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/1*3_2zDivWp758eLvJPhp8Aw.png"
        },
        {
          "id": "https://medium.com/p/ee9b0b0ef082",
          "author": "Naomi Kriger",
          "description": "How to Create a Speech-to-Text-to-Speech Program",
          "link": "https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-11T15:47:58.000Z",
          "wordCount": 4225,
          "title": "Speech to Text to Speech with AI Using Python — a How-To Guide",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*Ai0UNZUQI8jW0nau"
        },
        {
          "id": "https://medium.com/p/6abe3e8b045c",
          "author": "Nate Cibik",
          "description": "Multilingual Learning with an Ollama-Python Walkie-Talkie",
          "link": "https://towardsdatascience.com/lingonaut-language-assistant-6abe3e8b045c?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-11T15:17:09.000Z",
          "wordCount": 5607,
          "title": "LingoNaut Language Assistant",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1024/1*uxOckzPs6zbkuQZM80C7NA.jpeg"
        },
        {
          "id": "https://medium.com/p/e66b65ece369",
          "author": "Andy McDonald",
          "description": "Bringing Order to a Python Streamlit App Through an Organised Project Folder Structure\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/how-to-structure-and-organise-a-streamlit-app-e66b65ece369?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-11T15:04:44.000Z",
          "wordCount": 1504,
          "title": "How to Structure and Organise a Streamlit App",
          "imageUrl": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*PWOSQYW83vqbv4c-"
        },
        {
          "id": "https://medium.com/p/a191965ac538",
          "author": "Mike Shakhomirov",
          "description": "Advanced techniques to process and load data efficiently\nContinue reading on Towards Data Science »",
          "link": "https://towardsdatascience.com/pandas-for-data-engineers-a191965ac538?source=rss----7f60cf5620c9---4",
          "publishedOn": "2024-02-10T16:50:07.000Z",
          "wordCount": 1515,
          "title": "Pandas for Data Engineers",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1024/1*v64M9uKn1Yqs_ly80ucq5Q.png"
        }
      ]
    },
    {
      "title": "Machine Learning Blog | ML@CMU | Carnegie Mellon University",
      "feedUrl": "https://blog.ml.cmu.edu/feed/",
      "siteUrl": "https://blog.ml.cmu.edu",
      "articles": []
    },
    {
      "title": "Apple Machine Learning Research",
      "feedUrl": "https://machinelearning.apple.com/rss.xml",
      "siteUrl": "https://machinelearning.apple.com",
      "articles": [
        {
          "id": "resource-constrained",
          "author": null,
          "description": "We study the problem of stereo singing voice cancellation, a subtask of music source separation, whose goal is to estimate an instrumental background from a stereo mix. We explore how to achieve performance similar to large state-of-the-art source separation networks starting from a small, efficient model for real-time speech separation. Such a model is useful when memory and compute are limited and singing voice processing has to run with limited look-ahead. In practice, this is realised by adapting an existing mono model to handle stereo input. Improvements in quality are obtained by tuning…",
          "link": "https://machinelearning.apple.com/research/resource-constrained",
          "publishedOn": "2024-02-13T00:00:00.000Z",
          "wordCount": 2406,
          "title": "Resource-constrained Stereo Singing Voice Cancellation",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "autoregressive-image-models",
          "author": null,
          "description": "This paper introduces AIM, a collection of vision models pre-trained with an autoregressive objective. These models are inspired by their textual counterparts, i.e., Large Language Models (LLMs), and exhibit similar scaling properties. Specifically, we highlight two key findings: (1) the performance of the visual features scale with both the model capacity and the quantity of data, (2) the value of the objective function correlates with the performance of the model on downstream tasks. We illustrate the practical implication of these findings by pre-training a 7 billion parameter AIM on 2…",
          "link": "https://machinelearning.apple.com/research/autoregressive-image-models",
          "publishedOn": "2024-02-01T00:00:00.000Z",
          "wordCount": 1259,
          "title": "Scalable Pre-training of Large Autoregressive Image Models",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "acoustic-model-fusion",
          "author": null,
          "description": "Recent advances in deep learning and automatic speech recognition (ASR) have enabled the end-to-end (E2E) ASR system and boosted its accuracy to a new level. The E2E systems implicitly model all conventional ASR components, such as the acoustic model (AM) and the language model (LM), in a single network trained on audio-text pairs. Despite this simpler system architecture, fusing a separate LM, trained exclusively on text corpora, into the E2E system has proven to be beneficial. However, the application of LM fusion presents certain drawbacks, such as its inability to address the domain…",
          "link": "https://machinelearning.apple.com/research/acoustic-model-fusion",
          "publishedOn": "2024-01-29T00:00:00.000Z",
          "wordCount": 3302,
          "title": "Acoustic Model Fusion for End-to-end Speech Recognition",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "large-scale-training",
          "author": null,
          "description": "Tracking biosignals is crucial for monitoring wellness and preempting the development of severe medical conditions. Today, wearable devices can conveniently record various biosignals, creating the opportunity to monitor health status without disruption to one's daily routine. Despite the widespread use of wearable devices and existing digital biomarkers, the absence of curated data with annotated medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to other domains, which is an obstacle for…",
          "link": "https://machinelearning.apple.com/research/large-scale-training",
          "publishedOn": "2024-01-29T00:00:00.000Z",
          "wordCount": 1158,
          "title": "Large-scale Training of Foundation Models for Wearable Biosignals",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "flexible-keyword",
          "author": null,
          "description": "Spotting user-defined/flexible keywords represented in text frequently uses an expensive text encoder for joint analysis with an audio encoder in an embedding space, which can suffer from heterogeneous modality representation (for example, large mismatch) and increased complexity. In this work, we propose a novel architecture to efficiently detect arbitrary keywords based on an audio-compliant text encoder, which inherently has homogeneous representation with audio embedding, and it is also much smaller than a compatible text encoder. Our text encoder converts the text to phonemes using a…",
          "link": "https://machinelearning.apple.com/research/flexible-keyword",
          "publishedOn": "2024-01-29T00:00:00.000Z",
          "wordCount": 1015,
          "title": "Flexible Keyword Spotting based on Homogeneous Audio-Text Embedding",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "investigating-salient-representation",
          "author": null,
          "description": "Representations from models such as Bidirectional Encoder Representations from Transformers (BERT) and Hidden units BERT (HuBERT) have helped to achieve state-of-the-art performance in dimensional speech emotion recognition. Both HuBERT, and BERT models generate fairly large dimensional representations, and such models were not trained with emotion recognition task in mind. Such large dimensional representations result in speech emotion models with large parameter size, resulting in both memory and computational cost complexities. In this work, we investigate the selection of representations…",
          "link": "https://machinelearning.apple.com/research/investigating-salient-representation",
          "publishedOn": "2024-01-29T00:00:00.000Z",
          "wordCount": 1038,
          "title": "Investigating Salient Representations and Label Variance Modeling in Dimensional Speech Emotion Analysis",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "coml",
          "author": null,
          "description": "Machine learning (ML) models are fundamentally shaped by data, and building inclusive ML systems requires significant considerations around how to design representative datasets. Yet, few novice-oriented ML modeling tools are designed to foster hands-on learning of dataset design practices, including how to design for data diversity and inspect for data quality.\nTo this end, we outline a set of four data design practices (DDPs) for designing inclusive ML models and share how we designed a tablet-based application called Co-ML to foster the learning of DDPs through a collbaborative ML model…",
          "link": "https://machinelearning.apple.com/research/coml",
          "publishedOn": "2024-01-29T00:00:00.000Z",
          "wordCount": 1957,
          "title": "Co-ML: Collaborative Machine Learning Model Building for Developing Dataset Design Practices",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "user-level-differentially",
          "author": null,
          "description": "We study differentially private stochastic convex optimization (DP-SCO) under user-level privacy where each user may hold multiple data items. Existing work for  user-level DP-SCO either requires super-polynomial runtime or requires number of users that grows polynomially with the dimensionality of the problem. We develop new algorithms for user-level DP-SCO that obtain optimal rates, run in polynomial time, and require a number of users that grow logarithmically in the dimension. Moreover, our algorithms are the first  to obtain optimal rates for non-smooth functions in polynomial time. These…",
          "link": "https://machinelearning.apple.com/research/user-level-differentially",
          "publishedOn": "2024-01-29T00:00:00.000Z",
          "wordCount": 3172,
          "title": "User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "transport-solvers",
          "author": null,
          "description": "Two salient limitations have long hindered the relevance of optimal transport methods to machine learning. First, the  computational cost of standard sample-based solvers (when used on batches of  samples) is prohibitive. Second, the mass conservation constraint makes OT solvers too rigid in practice: because they must match \\textit{all} points from both measures, their output can be heavily influenced by outliers. A flurry of recent works has addressed these computational and modeling limitations. Still it has resulted in two separate strains of methods: While the computational outlook was…",
          "link": "https://machinelearning.apple.com/research/transport-solvers",
          "publishedOn": "2024-01-22T00:00:00.000Z",
          "wordCount": 2210,
          "title": "Unbalanced Low-Rank Optimal Transport Solvers",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "hybrid-model-learning",
          "author": null,
          "description": "This paper was accepted at the workshop Deep Generative Models for Health at NeurIPS 2023.\nCardiovascular diseases (CVDs) are a major global health concern, making the longitudinal monitoring of cardiovascular biomarkers vital for early diagnosis and intervention. A core challenge is the inference of cardiac pulse parameters from pulse waves, especially when acquired from wearable sensors at peripheral body locations. Traditional machine learning (ML) approaches face hurdles in this context due to the scarcity of labeled data, primarily sourced from clinical settings. Simultaneously, physical…",
          "link": "https://machinelearning.apple.com/research/hybrid-model-learning",
          "publishedOn": "2024-01-22T00:00:00.000Z",
          "wordCount": 4466,
          "title": "Hybrid Model Learning for Cardiovascular Biomarkers Inference",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "one-wide-ffn",
          "author": null,
          "description": "This paper was accepted at WMT conference at EMNLP.\nThe Transformer architecture has two main non-embedding components: Attention and the Feed Forward Network (FFN). Attention captures interdependencies between words regardless of their position, while the FFN non-linearly transforms each input token independently. In this work, we explore the role of FFN and find that despite, and find that despite taking up a significant fraction of the model's parameters, it is highly redundant. Concretely, we are able to substantially reduce the number of parameters with only a modest drop in accuracy by…",
          "link": "https://machinelearning.apple.com/research/one-wide-ffn",
          "publishedOn": "2024-01-22T00:00:00.000Z",
          "wordCount": 5315,
          "title": "One Wide Feedforward is All You Need",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        },
        {
          "id": "faster-nerf",
          "author": null,
          "description": "Super-resolution (SR) techniques have recently been proposed to upscale the outputs of neural radiance fields (NeRF) and generate high-quality images with enhanced inference speeds. However, existing NeRF+SR methods increase training overhead by using extra input features, loss functions, and/or expensive training procedures such as knowledge distillation. In this paper, we aim to leverage SR for efficiency gains without costly training or architectural changes. Specifically, we build a simple NeRF+SR pipeline that directly combines existing modules, and we propose a lightweight augmentation…",
          "link": "https://machinelearning.apple.com/research/faster-nerf",
          "publishedOn": "2024-01-22T00:00:00.000Z",
          "wordCount": 1050,
          "title": "FastSR-NeRF: Improving NeRF Efficiency on Consumer Devices with A Simple Super-Resolution Pipeline",
          "imageUrl": "https://mlr.cdn-apple.com/media/Home_1200x630_48225d82e9.png"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "https://blog.research.google/atom.xml",
      "siteUrl": "http://blog.research.google/",
      "articles": [
        {
          "id": "http://blog.research.google/2024/02/learning-importance-of-training-data.html",
          "author": null,
          "description": "Posted by Nishant Jain, Pre-doctoral Researcher, and Pradeep Shenoy, Research Scientist, Google Research\n\n\n\n\nThe constantly changing nature of the world around us poses a significant challenge for the development of AI models. Often, models are trained on longitudinal data with the hope that the training data used will accurately represent inputs the model may receive in the future. More generally, the default assumption that all training data are equally relevant often breaks in practice. For example, the figure below shows images from the CLEAR nonstationary learning benchmark, and it illustrates how visual features of objects evolve significantly over a 10 year span (a phenomenon we refer to as slow concept drift), posing a challenge for object categorization models. \n\n\n\n\n\n\n\n\nSample ima…",
          "link": "http://blog.research.google/2024/02/learning-importance-of-training-data.html",
          "publishedOn": "2024-02-14T18:32:00.000Z",
          "wordCount": 27743,
          "title": "Learning the importance of training data under concept drift",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgUeskw4YD6cFTpLaRnv7OwMsljyeipfAb1riYxIuBsiWd6TBmUXMJ4QoI9tlvUzWX9NzBbEjz3-P2Zl2kuXe5BrVclmqQFrLButoya5phiEELq1azrhsIaGaCz-ov_jXaMsFrGRDE0EjotyRQPOX3xV5MAkVJfKp9xecX4t2CoLBiZ8r2RpZ25Y5KRitFG/w1200-h630-p-k-no-nu/temporalreweightinghero.png"
        },
        {
          "id": "http://blog.research.google/2024/02/dp-auditorium-flexible-library-for.html",
          "author": null,
          "description": "Posted by Mónica Ribero Díaz, Research Scientist, Google Research\n\n\n\n\n\nDifferential privacy (DP) is a property of randomized mechanisms that limit the influence of any individual user’s information while processing and analyzing data. DP offers a robust solution to address growing concerns about data protection, enabling technologies across industries and government applications (e.g., the US census) without compromising individual user identities.  As its adoption increases, it’s important to identify the potential risks of developing mechanisms with faulty implementations. Researchers have recently found errors in the mathematical proofs of private mechanisms, and their implementations. For example, researchers compared six sparse vector technique (SVT) variations and found that only two…",
          "link": "http://blog.research.google/2024/02/dp-auditorium-flexible-library-for.html",
          "publishedOn": "2024-02-13T22:11:00.000Z",
          "wordCount": 27935,
          "title": "DP-Auditorium: A flexible library for auditing differential privacy",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhNVpxjk-jj1rIYQ8AM3A-Syqxd3d8L8-wIy8NWwyobCXmTRK7mY9h94aJYgFCiC0gnehVFFoM8-in8HsOZjfhoNce03nbsrN5fxY07wADV6ULPC0POGmCc-8eL3OqA9KrDyzQxN38JKvh6xCmLV6FZ1g0UfaXtKORhtTy0WuJexlPqV6P2c9rPdg_W_5zP/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2024/02/graph-neural-networks-in-tensorflow.html",
          "author": null,
          "description": "Posted by Dustin Zelle, Software Engineer, Google Research, and Arno Eigenwillig, Software Engineer, CoreML\n\n\n\n\nObjects and their relationships are ubiquitous in the world around us, and relationships can be as important to understanding an object as its own attributes viewed in isolation — take for example transportation networks, production networks, knowledge graphs, or social networks. Discrete mathematics and computer science have a long history of formalizing such networks as graphs, consisting of nodes connected by edges in various irregular ways. Yet most machine learning (ML) algorithms allow only for regular and uniform relations between input objects, such as a grid of pixels, a sequence of words, or no relation at all. \n\n\n\n\nGraph neural networks, or GNNs for short, have emerged…",
          "link": "http://blog.research.google/2024/02/graph-neural-networks-in-tensorflow.html",
          "publishedOn": "2024-02-06T19:17:00.000Z",
          "wordCount": 27781,
          "title": "Graph neural networks in TensorFlow",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcnTwrjg8cyZhVY1c-qi2ZEenIrDlkmlKlX0GsAuiKiIoxUu6i-phANh8tsCG4mUm5i-7t3zdLwuwn5DCcuQI5FKq-C3eibPnuqfoLuKFUsx-I3Ovim1Teps_JKiKZH7XqgHupnsOa2Y3peUgWcPNYG4ZIqA2_KQwxJpflo0WM6gNW8tXg5eDndiWx_dKK/w1200-h630-p-k-no-nu/TFGNN%20hero.gif"
        },
        {
          "id": "http://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html",
          "author": null,
          "description": "Posted by Rajat Sen and Yichen Zhou, Google Research\n\n\n\n\n\nTime-series forecasting is ubiquitous in various domains, such as retail, finance, manufacturing, healthcare and natural sciences. In retail use cases, for example, it has been observed that improving demand forecasting accuracy can meaningfully reduce inventory costs and increase revenue. Deep learning (DL) models have emerged as a popular approach for forecasting rich, multivariate, time-series data because they have proven to perform well in a variety of settings (e.g., DL models performed well in the M5 competition).\n\n\n\nAt the same time, there has been rapid progress in large foundation language models used for natural language processing (NLP) tasks, such as translation, retrieval-augmented generation, and code completion. Thes…",
          "link": "http://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html",
          "publishedOn": "2024-02-02T19:07:00.000Z",
          "wordCount": 27728,
          "title": "A decoder-only foundation model for time-series forecasting",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjLAVI4q3e6yNyTPTCFiLZVQfFm71GOX1TosHg_Sb8M6tVSO1hyphenhyphenZccOlufnqSuXP1rVWHmqHcely6fgW1vex4JdxenniJcaJ7TOomZolUFut8RUdxnOFZDrbt0hrIHkcrK7rl6cq5-kUuWGrOYqIirPAKtnf4vMDauPX4lFAz2PQjiqzqHxMna7eja9gOF/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2024/02/intervening-on-early-readouts-for.html",
          "author": null,
          "description": "Posted by Rishabh Tiwari, Pre-doctoral Researcher, and Pradeep Shenoy, Research Scientist, Google Research\n\n\n\n\nMachine learning models in the real world are often trained on limited data that may contain unintended statistical biases. For example, in the CELEBA celebrity image dataset, a disproportionate number of female celebrities have blond hair, leading to classifiers incorrectly predicting “blond” as the hair color for most female faces — here, gender is a spurious feature for predicting hair color. Such unfair biases could have significant consequences in critical applications such as medical diagnosis. \n\n\n\n\n\nSurprisingly, recent work has also discovered an inherent tendency of deep networks to amplify such statistical biases, through the so-called simplicity bias of deep learning. T…",
          "link": "http://blog.research.google/2024/02/intervening-on-early-readouts-for.html",
          "publishedOn": "2024-02-02T17:49:00.000Z",
          "wordCount": 27761,
          "title": "Intervening on early readouts for mitigating spurious features and simplicity bias",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdBd5rMRA2U1nd8fetuEweTgmHncn49ASMQtPlm6dfsr5V29RwsoUR8UtK4B7oSE1eiIdW-vD-gjCUK4tGZTbsY4XdO0adL2YtAjpgbF1S3mL_Jw3f31SwLKYUtCOLJ807gdXdRmD5iVsrtc_Ii-BiqQacv89vbtRbNAIINa9PhKAF_sDAZu09FLs4599T/w1200-h630-p-k-no-nu/SiFer%20Hero.png"
        },
        {
          "id": "http://blog.research.google/2024/01/mobilediffusion-rapid-text-to-image.html",
          "author": null,
          "description": "Posted by Yang Zhao, Senior Software Engineer, and Tingbo Hou, Senior Staff Software Engineer, Core ML\n\n\n\n\nText-to-image diffusion models have shown exceptional capabilities in generating high-quality images from text prompts. However, leading models feature billions of parameters and are consequently expensive to run, requiring powerful desktops or servers (e.g., Stable Diffusion, DALL·E, and Imagen). While recent advancements in inference solutions on Android via MediaPipe and iOS via Core ML have been made in the past year, rapid (sub-second) text-to-image generation on mobile devices has remained out of reach.\n \n\nTo that end, in “MobileDiffusion: Subsecond Text-to-Image Generation on Mobile Devices”, we introduce a novel approach with the potential for rapid text-to-image generation on…",
          "link": "http://blog.research.google/2024/01/mobilediffusion-rapid-text-to-image.html",
          "publishedOn": "2024-01-31T21:59:00.000Z",
          "wordCount": 27727,
          "title": "MobileDiffusion: Rapid text-to-image generation on-device",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOndf55Pc7tkXJektbVBEYRsOlxbUVui2uwOdXvuHj9cNpoNw2One4-68fqFNl2_fvv11CcgYfoI1XVQIkpjA9DosaOeqdkIRj9aZZJNoDy8KqB_XCVDtDd_EvT5UGL2ZhXvL2PU3RjN8XBjI0eQe8VIJCKI0-20AG0TKGK58mO9tBZa80P58KSjTU_liK/w1200-h630-p-k-no-nu/InstantTIGO%20hero.png"
        },
        {
          "id": "http://blog.research.google/2024/01/mixed-input-matrix-multiplication.html",
          "author": null,
          "description": "Posted by Manish Gupta, Staff Software Engineer, Google Research\n\n\n\n\nAI-driven technologies are weaving themselves into the fabric of our daily routines, with the potential to enhance our access to knowledge and boost our overall productivity. The backbone of these applications lies in large language models (LLMs).  LLMs are memory-intensive and typically require specialized hardware accelerators to efficiently deliver tens of exaflops of computing power. This blog post shows how we can start addressing the computational challenges by utilizing memory more effectively.\n\n\n\nThe bulk of an LLM’s memory and compute are consumed by weights in matrix multiplication operations. Using narrower data types reduces memory consumption. For example, storing weights in the 8-bit integer (i.e., U8 or S8)…",
          "link": "http://blog.research.google/2024/01/mixed-input-matrix-multiplication.html",
          "publishedOn": "2024-01-26T19:56:00.000Z",
          "wordCount": 27947,
          "title": "Mixed-input matrix multiplication performance optimizations",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEKJJf1R773hab0veY6zffF2Nf_yfV2mk8YU9yRnuBDD3ak1o0iXecWlJw2x7bL-Ez2MX1c21MXk65VMK5IsoLpJ1H6BTC6k7BvVWl_gHJpJIOG2cm3BwP4V-HCScGHYIynuskbhvu1uorQGprHGbOFmfGI7E5UWemJcZ0xSC3tC5DolBYgyBwugl6OOLr/w1200-h630-p-k-no-nu/matrixhero.png"
        },
        {
          "id": "http://blog.research.google/2024/01/exphormer-scaling-transformers-for.html",
          "author": null,
          "description": "Posted by Ameya Velingker, Research Scientist, Google Research, and Balaji Venkatachalam, Software Engineer, Google\n\n\n\n\nGraphs, in which objects and their relations are represented as nodes (or vertices) and edges (or links) between pairs of nodes, are ubiquitous in computing and machine learning (ML). For example, social networks, road networks, and molecular structure and interactions are all domains in which underlying datasets have a natural graph structure. ML can be used to learn the properties of nodes, edges, or entire graphs. \n\n\n\n\nA common approach to learning on graphs are graph neural networks (GNNs), which operate on graph data by applying an optimizable transformation on node, edge, and global attributes. The most typical class of GNNs operates via a message-passing framework,…",
          "link": "http://blog.research.google/2024/01/exphormer-scaling-transformers-for.html",
          "publishedOn": "2024-01-23T22:27:00.000Z",
          "wordCount": 27895,
          "title": "Exphormer: Scaling transformers for graph-structured data",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbovKreBr7RlKc4L36E6rLqiZBZzJSq5GLijCkomHREon5tYXd-7C2pppMXnL5Mj2d82kZGnPlarrrMzQOfRnN8kVvqDh1GnadIJ-hbaaS8VjYzCpaD-DgYor5cKx-OhTGZk9iCy5MjtwG2Q9eTyQiipDr5ViMdl2vkxfbLzWnB3wmLb8YfvVsTJ1FnOmw/w1200-h630-p-k-no-nu/EXPHORMER%2005large.gif"
        },
        {
          "id": "http://blog.research.google/2024/01/introducing-aspire-for-selective.html",
          "author": null,
          "description": "Posted by Jiefeng Chen, Student Researcher, and Jinsung Yoon, Research Scientist, Cloud AI Team\n\n\n\n\n\nIn the fast-evolving landscape of artificial intelligence, large language models (LLMs) have revolutionized the way we interact with machines, pushing the boundaries of natural language understanding and generation to unprecedented heights. Yet, the leap into high-stakes decision-making applications remains a chasm too wide, primarily due to the inherent uncertainty of model predictions. Traditional LLMs generate responses recursively, yet they lack an intrinsic mechanism to assign a confidence score to these responses. Although one can derive a confidence score by summing up the probabilities of individual tokens in the sequence, traditional approaches typically fall short in reliably dist…",
          "link": "http://blog.research.google/2024/01/introducing-aspire-for-selective.html",
          "publishedOn": "2024-01-18T18:03:00.000Z",
          "wordCount": 27602,
          "title": "Introducing ASPIRE for selective prediction in LLMs",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMaqP9dd9YDXh04PEWHSFquEToz6U5M4YUxzfExokjfteUfuGAKhqs1LV5DUMJOBoiF3GjGxg7NqezNazuTeWePMsuH_OW7NM4z4ooMPhWnR22iyzENgpmG2-xJDbRbeeyyLbG-3dIdgYjl2IxX0K-bFvpbrAJsQA7Mu70MqxEuVFJXvwnP_-o4sPK8wYe/w1200-h630-p-k-no-nu/ASPIRE%20hero.jpg"
        }
      ]
    },
    {
      "title": "FastML",
      "feedUrl": "https://fastml.com/atom.xml",
      "siteUrl": "https://fastml.com/atom.xml",
      "articles": []
    },
    {
      "title": "Adit Deshpande",
      "feedUrl": "https://adeshpande3.github.io/feed.xml",
      "siteUrl": "https://adeshpande3.github.io",
      "articles": []
    },
    {
      "title": "Kaggle Blog - Medium",
      "feedUrl": "https://medium.com/feed/kaggle-blog",
      "siteUrl": "https://medium.com/kaggle-blog?source=rss----4b0982ce16a3---4",
      "articles": []
    },
    {
      "title": "Hugging Face - Blog",
      "feedUrl": "https://huggingface.co/blog/feed.xml",
      "siteUrl": "https://huggingface.co/blog",
      "articles": []
    },
    {
      "title": "Lil'Log",
      "feedUrl": "https://lilianweng.github.io/index.xml",
      "siteUrl": "https://lilianweng.github.io/",
      "articles": [
        {
          "id": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/",
          "author": null,
          "description": "[Special thank you to Ian Kivlichan for many useful pointers (E.g. the 100+ year old Nature paper “Vox populi”) and nice feedback. 🙏 ]\nHigh-quality data is the fuel for modern data deep learning model training. Most of the task-specific labeled data comes from human annotation, such as classification task or RLHF labeling (which can be constructed as classification format) for LLM alignment training. Lots of ML techniques in the post can help with data quality, but fundamentally human data collection involves attention to details and careful execution.",
          "link": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/",
          "publishedOn": "2024-02-05T00:00:00.000Z",
          "wordCount": 9024,
          "title": "Thinking about High-Quality Human Data",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed/",
      "siteUrl": "https://www.microsoft.com/en-us/research/",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1007274",
          "author": "Alyssa Hughes",
          "description": "Partner Research Manager and developer experience expert Nicole Forsgren talks about the future of software engineering with AI, why she loves tech, and her reliance on a spreadsheet and her gut when making career-changing decisions.\nThe post What’s Your Story: Nicole Forsgren appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/whats-your-story-nicole-forsgren/",
          "publishedOn": "2024-02-15T14:00:00.000Z",
          "wordCount": 9380,
          "title": "What’s Your Story: Nicole Forsgren",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/02/Nicole-Forsgren_WYS_TW_LI_FB_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1005408",
          "author": "Brenda Potts",
          "description": "Perhaps the greatest challenge – and opportunity – of LLMs is extending their powerful capabilities to solve problems beyond the data on which they have been trained, and to achieve comparable results with data the LLM has never seen.  This opens new possibilities in data investigation, such as identifying themes and semantic concepts with context […]\nThe post GraphRAG: Unlocking LLM discovery on narrative private data appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/",
          "publishedOn": "2024-02-13T20:00:00.000Z",
          "wordCount": 4510,
          "title": "GraphRAG: Unlocking LLM discovery on narrative private data",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/02/NEWGraphRag-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1004529",
          "author": "Alyssa Hughes",
          "description": "The emergence of large language models (LLMs) has revolutionized the way people create text and interact with computing. However, these models are limited in ensuring the accuracy of the content they generate and enforcing strict compliance with specific formats, such as JSON and other computer programming languages. Additionally, LLMs that process information from multiple sources […]\nThe post AI Controller Interface: Generative AI with a lightweight, LLM-integrated VM appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/ai-controller-interface-generative-ai-with-a-lightweight-llm-integrated-vm/",
          "publishedOn": "2024-02-07T22:00:00.000Z",
          "wordCount": 3267,
          "title": "AI Controller Interface: Generative AI with a lightweight, LLM-integrated VM",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AICI-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1004556",
          "author": "Alyssa Hughes",
          "description": "Research Focus: New Research Forum series explores bold ideas in the era of AI; LASER improves reasoning in language models; Cache-Efficient Top-k Aggregation over High Cardinality Large Datasets; Six Microsoft researchers named 2023 ACM Fellows.\nThe post Research Focus: Week of February 5, 2024 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-february-5-2024/",
          "publishedOn": "2024-02-07T17:00:00.000Z",
          "wordCount": 2849,
          "title": "Research Focus: Week of February 5, 2024",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/02/RF34-FB-TWITTER-LI-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1000779",
          "author": "Alyssa Hughes",
          "description": "Partner Software Architect Ivan Tashev talks about applying his expertise in audio signal processing to the design and study of audio components for Microsoft products such as Kinect and shares how a focus on what he can control has fueled professional success.\nThe post What’s Your Story: Ivan Tashev appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/whats-your-story-ivan-tashev/",
          "publishedOn": "2024-02-01T14:00:00.000Z",
          "wordCount": 6954,
          "title": "What’s Your Story: Ivan Tashev",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Ivan_T_WYS_TW_LI_FB_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1003470",
          "author": "Alyssa Hughes",
          "description": "Microsoft Research Forum (opens in new tab) is a new series of conversations that explore recent advances, bold new ideas, and important discussions within the global research community. Leading Microsoft researchers will share insights into their work, followed by live online discussions with audience participants. This post provides an overview of the inaugural Microsoft Research […]\nThe post Microsoft Research Forum: New series explores bold ideas in technology research in the era of AI appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-research-forum-new-series-explores-bold-ideas-in-technology-research-in-the-era-of-ai/",
          "publishedOn": "2024-01-31T21:00:00.000Z",
          "wordCount": 3168,
          "title": "Microsoft Research Forum: New series explores bold ideas in technology research in the era of AI",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Research-Forum-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1002579",
          "author": "Alyssa Hughes",
          "description": "Microsoft announces the AFMR Minority Serving Institutions grant recipients, advancing AI research focused on today’s most significant technical and societal challenges. The grant provides funding and access to Azure-hosted foundation models.\nThe post Announcing recipients of the AFMR Minority Serving Institutions grant appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/announcing-recipients-of-the-afmr-minority-serving-institutions-grant/",
          "publishedOn": "2024-01-30T17:00:00.000Z",
          "wordCount": 2511,
          "title": "Announcing recipients of the AFMR Minority Serving Institutions grant",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/AMFR_MSI-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1000743",
          "author": "Alyssa Hughes",
          "description": "On “Abstracts,” Jordan Ash & Dipendra Misra discuss the parameter reduction method LASER. Tune in to learn how selective removal of stored data alone can boost LLM performance, then sign up for Microsoft Research Forum for more on LASER & related topics.\nThe post Abstracts: January 25, 2024 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-january-25-2024/",
          "publishedOn": "2024-01-25T14:00:00.000Z",
          "wordCount": 4498,
          "title": "Abstracts: January 25, 2024",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/Episode-Laser_Abstracts_TW_LI_FB_1200x627.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=1001187",
          "author": "Alyssa Hughes",
          "description": "Welcome to Research Focus, a series of blog posts that highlights notable publications, events, code/datasets, new hires and other milestones from across the research community at Microsoft. Join Microsoft Research Forum (opens in new tab) for a continuous exchange of ideas about science and technology research in the era of general AI. This series, which begins […]\nThe post Research Focus: Week of January 22, 2024 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-january-22-2024/",
          "publishedOn": "2024-01-24T17:00:00.000Z",
          "wordCount": 2584,
          "title": "Research Focus: Week of January 22, 2024",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/RF33-FB-TWITTER-LI1200x627.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=999873",
          "author": "Alyssa Hughes",
          "description": "MetaOpt helps analyze, explain, and improve heuristic performance before deployment in production systems. Learn how it works, particularly in traffic engineering, packet scheduling, and VM placement.\nThe post MetaOpt: Examining, explaining, and improving heuristic performance appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/metaopt-examining-explaining-and-improving-heuristic-performance/",
          "publishedOn": "2024-01-23T17:00:00.000Z",
          "wordCount": 2980,
          "title": "MetaOpt: Examining, explaining, and improving heuristic performance",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MetaOpt-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=996564",
          "author": "Alyssa Hughes",
          "description": "The Global Health Drug Discovery Institute and Microsoft Research are using AI to innovate in life sciences by accelerating the development of new treatments for global infectious diseases like tuberculosis and COVID. Find out how.\nThe post GHDDI and Microsoft Research use AI technology to achieve significant progress in discovering new drugs to treat global infectious diseases appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/ghddi-and-microsoft-research-use-ai-technology-to-achieve-significant-progress-in-discovering-new-drugs-to-treat-global-infectious-diseases/",
          "publishedOn": "2024-01-16T17:00:00.000Z",
          "wordCount": 3392,
          "title": "GHDDI and Microsoft Research use AI technology to achieve significant progress in discovering new drugs to treat global infectious diseases",
          "enclosure": {
            "url": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/TB_dockingResults.mp4",
            "length": "6071874",
            "type": "video/mp4"
          },
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2024/01/GHDDI-TWLIFB-1200x627-1.jpg"
        }
      ]
    },
    {
      "title": "The Stanford AI Lab Blog",
      "feedUrl": "https://ai.stanford.edu/blog/feed.xml",
      "siteUrl": "http://ai.stanford.edu/blog/",
      "articles": []
    },
    {
      "title": "ruder.io",
      "feedUrl": "https://www.ruder.io/rss/",
      "siteUrl": "https://www.ruder.io/",
      "articles": []
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": []
    }
  ],
  "cliVersion": "1.15.1"
}